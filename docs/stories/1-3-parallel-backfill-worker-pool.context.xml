<?xml version="1.0" encoding="UTF-8"?>
<story-context id="1-3-parallel-backfill-worker-pool" v="1.0">
  <metadata>
    <epicId>1</epicId>
    <storyId>3</storyId>
    <title>Parallel Backfill Worker Pool</title>
    <status>drafted</status>
    <generatedAt>2025-10-30</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/1-3-parallel-backfill-worker-pool.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>blockchain indexer system</asA>
    <iWant>a parallel worker pool that efficiently backfills historical blocks from the blockchain</iWant>
    <soThat>I can quickly ingest large historical datasets (5,000+ blocks) using concurrent RPC requests and batch database inserts</soThat>
    <tasks>
      <task n="1" goal="Design backfill coordinator architecture" acs="1, 5">
        <subtask n="1.1">Design BackfillCoordinator struct with RPC client, ingester, store, worker config</subtask>
        <subtask n="1.2">Design worker pool pattern with job queue and result aggregation</subtask>
        <subtask n="1.3">Design configuration struct for worker count, batch size, height range</subtask>
        <subtask n="1.4">Design error aggregation (collect errors from workers, halt on first permanent error)</subtask>
        <subtask n="1.5">Document design patterns and architectural decisions</subtask>
      </task>
      <task n="2" goal="Implement worker pool with concurrent processing" acs="1, 2, 3">
        <subtask n="2.1">Create internal/index/backfill.go with BackfillCoordinator struct</subtask>
        <subtask n="2.2">Implement Backfill(ctx, startHeight, endHeight) method</subtask>
        <subtask n="2.3">Create worker goroutine function that fetches and parses blocks</subtask>
        <subtask n="2.4">Implement job queue (channel) for block heights</subtask>
        <subtask n="2.5">Implement result collector goroutine for batch aggregation</subtask>
        <subtask n="2.6">Implement sync.WaitGroup coordination between workers and main goroutine</subtask>
      </task>
      <task n="3" goal="Implement error handling and worker resilience" acs="3">
        <subtask n="3.1">Create error channel with worker context (worker ID, block height)</subtask>
        <subtask n="3.2">Implement error classification in backfill (transient vs permanent)</subtask>
        <subtask n="3.3">Handle worker panic recovery (avoid crash from single worker failure)</subtask>
        <subtask n="3.4">Implement early exit on permanent error (close channels, wait for goroutines)</subtask>
        <subtask n="3.5">Log errors with structured context (JSON logging)</subtask>
      </task>
      <task n="4" goal="Implement batch collection and database insertion" acs="2, 4">
        <subtask n="4.1">Create result collector that batches blocks (configurable batch size)</subtask>
        <subtask n="4.2">Call store.InsertBlocks() when batch reaches target size</subtask>
        <subtask n="4.3">Flush remaining blocks at end of backfill</subtask>
        <subtask n="4.4">Track insertion stats (batch count, total blocks inserted)</subtask>
        <subtask n="4.5">Handle database insertion errors (propagate to caller)</subtask>
      </task>
      <task n="5" goal="Add configuration and metrics" acs="5">
        <subtask n="5.1">Create internal/index/backfill_config.go with configuration struct</subtask>
        <subtask n="5.2">Load configuration from environment variables (BACKFILL_WORKERS, BACKFILL_BATCH_SIZE, height range)</subtask>
        <subtask n="5.3">Add Prometheus metrics (backfill_duration_seconds, blocks_backfilled_total, backfill_workers)</subtask>
        <subtask n="5.4">Log backfill summary (start time, end time, total blocks, throughput)</subtask>
        <subtask n="5.5">Add structured logging throughout backfill process</subtask>
      </task>
      <task n="6" goal="Write comprehensive tests" acs="1, 2, 3, 4, 5">
        <subtask n="6.1">Create internal/index/backfill_test.go with mocked RPC and database</subtask>
        <subtask n="6.2">Test backfill with small dataset (10 blocks, 2 workers) - verify all blocks fetched</subtask>
        <subtask n="6.3">Test worker failure resilience (mock RPC client failure on specific heights)</subtask>
        <subtask n="6.4">Test batch collection and insertion (verify InsertBlocks called correctly)</subtask>
        <subtask n="6.5">Test context cancellation (verify goroutine cleanup)</subtask>
        <subtask n="6.6">Test configuration validation (missing env vars, invalid values)</subtask>
        <subtask n="6.7">Performance test (measure throughput with mock RPC - target &gt;1000 blocks/sec)</subtask>
        <subtask n="6.8">Achieve &gt;70% test coverage for backfill package</subtask>
      </task>
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="1" title="Worker Pool Architecture">
      <requirement>Implements configurable worker pool with N concurrent workers (default: 8)</requirement>
      <requirement>Workers fetch blocks independently via RPC client</requirement>
      <requirement>Job queue distributes block heights across workers fairly</requirement>
      <requirement>Result aggregation collects blocks from workers without blocking</requirement>
    </criterion>
    <criterion id="2" title="Performance Targets">
      <requirement>Backfills 5,000 blocks in &lt;5 minutes with 8 workers</requirement>
      <requirement>Achieves ~16.7 blocks/second throughput (5000 blocks / 300 seconds)</requirement>
      <requirement>Database inserts happen in configurable batch sizes (default: 100 blocks)</requirement>
      <requirement>Parallel fetching keeps network latency hidden by worker pipeline</requirement>
    </criterion>
    <criterion id="3" title="Error Handling and Resilience">
      <requirement>Worker failures don't block entire backfill (continue with other workers)</requirement>
      <requirement>RPC errors propagate through error channel with context (worker ID, block height)</requirement>
      <requirement>Transient failures handled via RPC client retry logic (no additional retry in backfill)</requirement>
      <requirement>First permanent error halts backfill and returns error to caller</requirement>
    </criterion>
    <criterion id="4" title="Data Integrity">
      <requirement>Blocks inserted in order (or with ordering verification)</requirement>
      <requirement>Batch inserts maintain referential integrity (blocks before transactions before logs)</requirement>
      <requirement>No duplicate blocks inserted (idempotency)</requirement>
      <requirement>Foreign key constraints validated at database layer</requirement>
    </criterion>
    <criterion id="5" title="Configuration and Observability">
      <requirement>Worker count configurable via BACKFILL_WORKERS environment variable</requirement>
      <requirement>Batch size configurable via BACKFILL_BATCH_SIZE environment variable</requirement>
      <requirement>Height range configurable via BACKFILL_START_HEIGHT, BACKFILL_END_HEIGHT</requirement>
      <requirement>Progress metrics logged: blocks processed, batch count, duration, throughput</requirement>
      <requirement>Prometheus metrics: backfill_duration_seconds histogram, blocks_backfilled_total counter, backfill_workers gauge</requirement>
    </criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/tech-spec-epic-1.md</path>
        <title>Tech Spec: Epic 1 - Core Indexing &amp; Data Pipeline</title>
        <section>Story 1.3: Parallel Backfill Worker Pool</section>
        <snippet>Backfill coordinator with worker pool pattern (lines 669-789). Includes BackfillCoordinator struct, Backfill method implementation pattern, worker function, result collector, and configuration. Reference implementation for Go concurrency patterns.</snippet>
      </doc>
      <doc>
        <path>docs/solution-architecture.md</path>
        <title>Solution Architecture</title>
        <section>Indexing Layer</section>
        <snippet>Describes indexing layer responsibilities, backfill and live-tail coordination patterns, component boundaries, and performance requirements.</snippet>
      </doc>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>FR001: Historical Block Indexing</section>
        <snippet>Defines backfill requirements: 5,000 blocks initial scope, configurable ranges, performance targets (&lt;5 minutes), data integrity requirements.</snippet>
      </doc>
      <doc>
        <path>docs/epic-stories.md</path>
        <title>Epic and Story Breakdown</title>
        <section>Epic 1: Story 1.3</section>
        <snippet>Story breakdown with acceptance criteria, delivery order, dependencies, and integration points with Stories 1.1 and 1.2.</snippet>
      </doc>
      <doc>
        <path>docs/stories/1-1-ethereum-rpc-client-with-retry-logic.md</path>
        <title>Story 1.1: Ethereum RPC Client with Retry Logic</title>
        <section>Dev Agent Record, Senior Developer Review</section>
        <snippet>Completed RPC client with automatic retry logic, error classification, and structured logging. Key learning: 74.8% test coverage standard, input validation at API boundary patterns.</snippet>
      </doc>
      <doc>
        <path>docs/stories/1-2-postgresql-schema-and-migrations.md</path>
        <title>Story 1.2: PostgreSQL Schema and Migrations</title>
        <section>Dev Agent Record, Learnings from Previous Story</section>
        <snippet>Database schema with blocks/transactions/logs tables, pgxpool connection pooling. Key learning: 74.6% test coverage, environment variable configuration patterns, connection pooling for concurrent access.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>internal/rpc/client.go</path>
        <kind>service</kind>
        <symbol>Client, GetBlockByNumber, GetTransactionReceipt, ChainID</symbol>
        <lines>1-232</lines>
        <reason>RPC client to reuse for fetching blocks. GetBlockByNumber(ctx, height) is the primary method used by backfill workers. Already includes retry logic and error handling.</reason>
      </artifact>
      <artifact>
        <path>internal/rpc/errors.go</path>
        <kind>service</kind>
        <symbol>classifyError, ErrTransient, ErrPermanent, ErrRateLimit</symbol>
        <lines>1-109</lines>
        <reason>Error classification logic from RPC client. Backfill workers use these error types to handle transient vs permanent errors from RPC calls.</reason>
      </artifact>
      <artifact>
        <path>internal/db/connection.go</path>
        <kind>service</kind>
        <symbol>Pool, NewPool, InsertBlocks (interface), Close</symbol>
        <lines>1-95</lines>
        <reason>Database connection pool for inserting blocks. Store interface will use this pool. Connection pooling handles concurrent access from multiple batch inserts.</reason>
      </artifact>
      <artifact>
        <path>internal/db/config.go</path>
        <kind>service</kind>
        <symbol>Config, NewConfig, ConnectionString</symbol>
        <lines>1-143</lines>
        <reason>Configuration pattern for environment variables. Backfill config should follow similar pattern: load from environment, provide defaults, validate inputs.</reason>
      </artifact>
      <artifact>
        <path>go.mod</path>
        <kind>manifest</kind>
        <symbol>Dependencies</symbol>
        <lines>1-20</lines>
        <reason>Project dependencies. Key: go-ethereum v1.16.5 (for types.Block), prometheus/client_golang (for metrics), testify (for mocking in tests).</reason>
      </artifact>
    </code>
    <dependencies>
      <go>
        <package name="go-ethereum" version="v1.16.5" purpose="types.Block, types.Transaction, ethclient for RPC" required="true"/>
        <package name="pgx" version="v5.7.6+" purpose="Database driver for inserts via pool" required="true"/>
        <package name="prometheus/client_golang" version="latest" purpose="Prometheus metrics (counters, histograms)" required="false"/>
        <package name="testify" version="v1.10.0+" purpose="Mock and assert in tests" required="true"/>
        <stdlib name="sync" purpose="WaitGroup, Mutex for worker coordination" required="true"/>
        <stdlib name="context" purpose="Context.Context for cancellation and timeouts" required="true"/>
        <stdlib name="log/slog" purpose="Structured JSON logging (Go 1.21+)" required="true"/>
      </go>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint>
      <category>Architecture</category>
      <rule>Workers must be goroutines communicating via channels (no shared mutable state).</rule>
      <rule>Result collector runs in separate goroutine to aggregate blocks without blocking workers.</rule>
      <rule>Error channel shared across all workers; first error triggers early exit.</rule>
    </constraint>
    <constraint>
      <category>Concurrency</category>
      <rule>All operations must accept context.Context for cancellation support.</rule>
      <rule>Use sync.WaitGroup to coordinate worker lifecycle and ensure cleanup.</rule>
      <rule>Channel operations must be non-blocking where possible (use select with default or buffered channels).</rule>
      <rule>Defer cleanup (close channels, wait for goroutines) to prevent deadlocks or resource leaks.</rule>
    </constraint>
    <constraint>
      <category>Error Handling</category>
      <rule>Don't re-implement error classification; use RPC client's error types (ErrTransient, ErrPermanent).</rule>
      <rule>Log errors with context (worker ID, block height, attempt number).</rule>
      <rule>First permanent error should halt backfill (don't continue with other workers after error).</rule>
    </constraint>
    <constraint>
      <category>Testing</category>
      <rule>Mock RPC client to avoid external dependencies; use pre-generated test blocks.</rule>
      <rule>Mock database Store interface to verify InsertBlocks called with correct batches.</rule>
      <rule>Test coverage target: &gt;70% (Story 1.1: 74.8%, Story 1.2: 74.6%).</rule>
      <rule>Include performance test with mock to measure theoretical throughput (target &gt;1000 blocks/sec).</rule>
    </constraint>
    <constraint>
      <category>Configuration</category>
      <rule>Environment variables for all tunable parameters (BACKFILL_WORKERS, BACKFILL_BATCH_SIZE).</rule>
      <rule>Provide sensible defaults if env vars not set (workers: 8, batch size: 100).</rule>
      <rule>Validate configuration on startup (e.g., workers &gt;0, batch size &gt;0).</rule>
    </constraint>
    <constraint>
      <category>Logging</category>
      <rule>Use log/slog (JSON handler) for structured logging (established pattern from Story 1.1).</rule>
      <rule>Include context in all logs: timestamp, level, message, structured fields (worker_id, block_height, duration_ms).</rule>
      <rule>Log backfill summary at completion (total blocks, duration, throughput).</rule>
    </constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>BackfillCoordinator.Backfill</name>
      <kind>method</kind>
      <signature>func (bc *BackfillCoordinator) Backfill(ctx context.Context, startHeight, endHeight uint64) error</signature>
      <path>internal/index/backfill.go (to be created)</path>
      <purpose>Public entry point for backfill operation. Manages worker lifecycle, job distribution, result collection, and error handling.</purpose>
    </interface>
    <interface>
      <name>rpc.Client.GetBlockByNumber</name>
      <kind>method</kind>
      <signature>func (c *Client) GetBlockByNumber(ctx context.Context, height uint64) (*types.Block, error)</signature>
      <path>internal/rpc/client.go:71-137</path>
      <purpose>Fetch block from Ethereum RPC. Used by worker goroutines to fetch blocks by height.</purpose>
    </interface>
    <interface>
      <name>store.Store.InsertBlocks</name>
      <kind>interface</kind>
      <signature>type Store interface { InsertBlocks(ctx context.Context, blocks []*ingest.Block) error }</signature>
      <path>internal/store/ (to be created)</path>
      <purpose>Batch insert blocks into database. Called by result collector with block batches.</purpose>
    </interface>
    <interface>
      <name>ingest.Ingester.ParseBlock</name>
      <kind>method</kind>
      <signature>func (i *Ingester) ParseBlock(block *types.Block) *ingest.Block</signature>
      <path>internal/ingest/ (to be created in later story)</path>
      <purpose>Convert go-ethereum types.Block to domain model ingest.Block. Used by workers after fetching from RPC.</purpose>
    </interface>
  </interfaces>

  <tests>
    <standards>
      <paragraph>Unit tests use table-driven approach with mocked RPC and Store interfaces (testify/mock). Integration tests prefer test database containers when needed. Benchmarks measure throughput with mock data. All tests accept context.Context for cancellation simulation. Coverage target: &gt;70% (established baseline from Stories 1.1 and 1.2). Tests organized by concern: TestBackfill_HappyPath, TestBackfill_WorkerFailure, TestBackfill_ContextCancellation, etc.</paragraph>
    </standards>
    <locations>
      <location>internal/index/backfill_test.go - Primary test file for backfill package</location>
      <location>internal/index/*_test.go - Any additional unit/integration tests</location>
    </locations>
    <ideas>
      <idea ac="1" title="Happy Path: Backfill 10 blocks with 2 workers">Verify all blocks fetched, inserted in correct batches, workers coordinate via channels without deadlock.</idea>
      <idea ac="2" title="Performance: Measure throughput with mock">Mock RPC client returns instantly; measure blocks/second. Target &gt;1000 blocks/sec with mock (RPC latency removed).</idea>
      <idea ac="3" title="Worker Failure: Mock RPC error on specific heights">Some workers fail; others continue. First error should halt backfill without crashing remaining workers.</idea>
      <idea ac="3" title="Panic Recovery: Simulate worker panic">Worker goroutine panics (e.g., division by zero); verify backfill handles gracefully (no total crash).</idea>
      <idea ac="4" title="Batch Collection: Verify batches size and count">InsertBlocks called with correct batch sizes; final batch may be smaller; no batches skipped or duplicated.</idea>
      <idea ac="5" title="Configuration Validation: Missing or invalid env vars">BACKFILL_WORKERS=0, negative batch size, invalid height range. Verify sensible error messages.</idea>
      <idea ac="5" title="Context Cancellation: Cancel mid-backfill">Cancel context; verify workers stop cleanly, no goroutine leaks, results flushed before exit.</idea>
      <idea ac="1,2,5" title="Concurrent Access: Multiple batches from concurrent workers">Verify database pool handles concurrent inserts without connection exhaustion or race conditions.</idea>
    </ideas>
  </tests>
</story-context>
